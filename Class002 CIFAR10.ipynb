{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径\n",
    "DATA_PATH = './cifar/'\n",
    "# 如果数据集不存在是否下载数据集\n",
    "DOWNLOAD_DATASET = True\n",
    "# 批量大小\n",
    "BATCH_SIZE = 50\n",
    "# 设置是否使用GPU\n",
    "USEGPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于读取表格数据\n",
    "import pandas as pd\n",
    "# 用于构建神经网络和相应数据处理\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "# 用于图像的读取和基本处理\n",
    "import cv2 as cv\n",
    "# 用于支持其他模块以及非torch的矩阵操作\n",
    "import numpy as np\n",
    "# 用于显示图像\n",
    "import matplotlib.pyplot as plt\n",
    "# 用于计算训练用时\n",
    "import datetime\n",
    "# 用于XML文件读写\n",
    "import xml.etree.ElementTree as ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 确定正在使用的运算设备\n",
    "if USEGPU:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print('using',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.4733630244453624\n",
      "std 0.2515689271173141\n"
     ]
    }
   ],
   "source": [
    "# 这一部分把三个通道合到一起计算了。\n",
    "# 应该分开算\n",
    "\n",
    "# 如果没有记录的平均值和标准差\n",
    "# 就计算训练集的平均值和标准差并保存\n",
    "# 如果已经存在\n",
    "# 则读取均值和方差\n",
    "# 初始化平均值和标准差的存储变量\n",
    "datasetMean = 0\n",
    "datasetStd = 0\n",
    "# 初始化文件路径\n",
    "xmlFilePath = DATA_PATH+'TrainsetMeanAndStd.xml'\n",
    "# 尝试读取数据\n",
    "try:\n",
    "    tree = ElementTree.parse(xmlFilePath)\n",
    "    rootNode = tree.getroot()\n",
    "    for node in rootNode:\n",
    "        if node.tag == 'mean':\n",
    "            datasetMean = float(node.attrib['value'])\n",
    "        elif node.tag =='std':\n",
    "            datasetStd = float(node.attrib['value'])\n",
    "except:\n",
    "    # 如果读取失败则重新计算均值和方差\n",
    "    # 计算均值和方差之前先要保证训练集存在\n",
    "    train_data = torchvision.datasets.CIFAR10(root=DATA_PATH, train=True,download=DOWNLOAD_DATASET, \n",
    "                                        transform=torchvision.transforms.ToTensor())\n",
    "    print('计算训练集数据均值和方差中')\n",
    "    # 计算平均值\n",
    "    tempSum = 0\n",
    "    for i, data in enumerate(train_data):\n",
    "        img, label = data\n",
    "        tempSum = tempSum + float(img.mean())\n",
    "    datasetMean = tempSum/len(train_data)\n",
    "    # 计算标准差\n",
    "    tempSum = 0\n",
    "    for i, data in enumerate(train_data):\n",
    "        img, label = data\n",
    "        tempSum = tempSum + float(((img-datasetMean)**2).mean())\n",
    "    datasetStd = (tempSum/len(train_data))**0.5\n",
    "    print('计算完毕')\n",
    "    # 生成XML并保存\n",
    "    rootNode = ElementTree.Element('root')\n",
    "    meanNode = ElementTree.SubElement(rootNode,'mean')\n",
    "    meanNode.attrib = {'value':str(datasetMean)}\n",
    "    stdNode = ElementTree.SubElement(rootNode,'std')\n",
    "    stdNode.attrib = {'value':str(datasetStd)}\n",
    "    tree = ElementTree.ElementTree(rootNode)\n",
    "    # 生成的XML保存于DATA_PATH路径之下\n",
    "    tree.write(xmlFilePath)\n",
    "print('mean',datasetMean)\n",
    "print('std',datasetStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 如果上边改成三通道这里也要修改\n",
    "datasetMean = (datasetMean,datasetMean,datasetMean)\n",
    "datasetStd = (datasetStd,datasetStd,datasetStd)\n",
    "# CIFAR数据集载入\n",
    "# 图像数据的归一化和正则化\n",
    "# 需要注意的是ToTensor转化器在加载数据的时候已经把图像像素值从[0,255]变成了[0.0,1.0]\n",
    "# 载入MNIST数据集\n",
    "# ToTensor可以把像素数据整理到[0.0,1.0]区间。\n",
    "\n",
    "# 构造转换器\n",
    "TF = torchvision.transforms\n",
    "transformFunction = TF.Compose([TF.ToTensor(),\n",
    "                                TF.Normalize(mean=datasetMean,std=datasetStd)\n",
    "                               ])\n",
    "#transformFunction = TF.Compose([TF.ToTensor(),])\n",
    "# 载入训练集和测试集\n",
    "train_data = torchvision.datasets.CIFAR10(root=DATA_PATH, train=True,download=DOWNLOAD_DATASET, \n",
    "                                        transform=transformFunction)\n",
    "test_data = torchvision.datasets.CIFAR10(root=DATA_PATH, train=False,download=DOWNLOAD_DATASET, \n",
    "                                        transform=transformFunction)\n",
    "# 用DataLoader把数据集打包起来\n",
    "Data = torch.utils.data\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class ClassificationCIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationCIFAR10,self).__init__()\n",
    "        self.n1=nn.Sequential(nn.Conv2d(3, 4, 3, 1),nn.ReLU(), nn.MaxPool2d(kernel_size=2))\n",
    "        self.n2=nn.Sequential(nn.Conv2d(4, 8, 3, 1),nn.ReLU(), nn.MaxPool2d(kernel_size=2))\n",
    "        #self.n3=nn.Sequential(nn.Conv2d(8, 16, 3, 1),nn.ReLU(), nn.MaxPool2d(kernel_size=2))\n",
    "        self.fc1 = nn.Linear(8*6*6,10)\n",
    "        #self.fc2 = nn.Linear(33,15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.n1(x)\n",
    "        x = self.n2(x)\n",
    "        #x = self.n3(x)\n",
    "        x = x.view(-1,8*6*6)\n",
    "        x = self.fc1(x)\n",
    "       #x = self.fc2(x)\n",
    "        #output = (torch.sigmoid(x)).round()\n",
    "        output = torch.sigmoid(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化网络，及相关函数\n",
    "cnn=ClassificationCIFAR10().to(device)\n",
    "EPOCH = 20\n",
    "#LR = 0.001\n",
    "#LR = 0.0001\n",
    "# 学习率是个超参数，这东西是实验出来的\n",
    "#LR = 0.001\n",
    "LR = 0.0001\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = torch.nn.CrossEntropyLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 114.8623 | test accuracy: 0.06\n",
      "Epoch:  0 | train loss: 108.0949 | test accuracy: 0.30\n",
      "Epoch:  1 | train loss: 106.2955 | test accuracy: 0.32\n",
      "Epoch:  1 | train loss: 97.9107 | test accuracy: 0.34\n",
      "Epoch:  2 | train loss: 102.7084 | test accuracy: 0.34\n",
      "Epoch:  2 | train loss: 102.7250 | test accuracy: 0.36\n",
      "Epoch:  3 | train loss: 99.1931 | test accuracy: 0.40\n",
      "Epoch:  3 | train loss: 100.7133 | test accuracy: 0.48\n",
      "Epoch:  4 | train loss: 99.9203 | test accuracy: 0.32\n",
      "Epoch:  4 | train loss: 97.9620 | test accuracy: 0.34\n",
      "Epoch:  5 | train loss: 99.8813 | test accuracy: 0.38\n",
      "Epoch:  5 | train loss: 103.1572 | test accuracy: 0.26\n",
      "Epoch:  6 | train loss: 97.0090 | test accuracy: 0.48\n",
      "Epoch:  6 | train loss: 97.5128 | test accuracy: 0.38\n",
      "Epoch:  7 | train loss: 98.4744 | test accuracy: 0.50\n",
      "Epoch:  7 | train loss: 96.1019 | test accuracy: 0.42\n",
      "Epoch:  8 | train loss: 97.1707 | test accuracy: 0.32\n",
      "Epoch:  8 | train loss: 101.0184 | test accuracy: 0.46\n",
      "Epoch:  9 | train loss: 97.9794 | test accuracy: 0.54\n",
      "Epoch:  9 | train loss: 100.8882 | test accuracy: 0.54\n",
      "Epoch:  10 | train loss: 97.6864 | test accuracy: 0.50\n",
      "Epoch:  10 | train loss: 98.8388 | test accuracy: 0.44\n",
      "Epoch:  11 | train loss: 94.3467 | test accuracy: 0.38\n",
      "Epoch:  11 | train loss: 97.3932 | test accuracy: 0.46\n",
      "Epoch:  12 | train loss: 97.4615 | test accuracy: 0.48\n",
      "Epoch:  12 | train loss: 100.3061 | test accuracy: 0.38\n",
      "Epoch:  13 | train loss: 94.1590 | test accuracy: 0.34\n",
      "Epoch:  13 | train loss: 97.6505 | test accuracy: 0.38\n",
      "Epoch:  14 | train loss: 93.3611 | test accuracy: 0.48\n",
      "Epoch:  14 | train loss: 100.4146 | test accuracy: 0.48\n",
      "Epoch:  15 | train loss: 97.9406 | test accuracy: 0.34\n",
      "Epoch:  15 | train loss: 95.9397 | test accuracy: 0.50\n",
      "Epoch:  16 | train loss: 95.2636 | test accuracy: 0.34\n",
      "Epoch:  16 | train loss: 97.8323 | test accuracy: 0.44\n",
      "Epoch:  17 | train loss: 95.5966 | test accuracy: 0.32\n",
      "Epoch:  17 | train loss: 95.4811 | test accuracy: 0.52\n",
      "Epoch:  18 | train loss: 92.5813 | test accuracy: 0.50\n",
      "Epoch:  18 | train loss: 93.2137 | test accuracy: 0.46\n",
      "Epoch:  19 | train loss: 95.5519 | test accuracy: 0.46\n",
      "Epoch:  19 | train loss: 93.9769 | test accuracy: 0.50\n",
      "Train time: 184 seconds\n"
     ]
    }
   ],
   "source": [
    "# 进行训练\n",
    "torch.cuda.synchronize()\n",
    "starttime=datetime.datetime.now()\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获取数据并把训练用数据转移到GPU上\n",
    "        b_x,b_y = data\n",
    "        b_x = b_x.to(device)\n",
    "        b_y = b_y.to(device)\n",
    "        # 前馈和计算损失\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "        # 反馈\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i% 500 == 0:\n",
    "            for j,testdata in enumerate(test_loader):\n",
    "                tx,ty =testdata\n",
    "                tx = tx.to(device)\n",
    "                ty = ty.to(device)\n",
    "                test_output = cnn(tx)\n",
    "                # !!!!!!!! Change in here !!!!!!!!! #\n",
    "                pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n",
    "                accuracy = torch.sum(pred_y == ty).type(torch.FloatTensor) / ty.size(0)\n",
    "                print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "                break\n",
    " \n",
    "\n",
    "torch.cuda.synchronize()\n",
    "endtime=datetime.datetime.now()\n",
    "print('Train time:',(endtime-starttime).seconds,'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# MNIST数据集载入\n",
    "# 图像数据的归一化和正则化\n",
    "# 需要注意的是ToTensor转化器在加载数据的时候已经把图像像素值从[0,255]变成了[0.0,1.0]\n",
    "# 载入MNIST数据集\n",
    "# ToTensor可以把像素数据整理到[0.0,1.0]区间。\n",
    "\n",
    "# 构造转换器\n",
    "TF = torchvision.transforms\n",
    "\n",
    "#transformFunction = TF.Compose([TF.ToTensor(),])\n",
    "# 载入训练集和测试集\n",
    "test_data = torchvision.datasets.CIFAR10(root=DATA_PATH, train=False,download=DOWNLOAD_DATASET, \n",
    "                                        transform=TF.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.6196, 0.6235, 0.6471,  ..., 0.5373, 0.4941, 0.4549],\n",
      "         [0.5961, 0.5922, 0.6235,  ..., 0.5333, 0.4902, 0.4667],\n",
      "         [0.5922, 0.5922, 0.6196,  ..., 0.5451, 0.5098, 0.4706],\n",
      "         ...,\n",
      "         [0.2667, 0.1647, 0.1216,  ..., 0.1490, 0.0510, 0.1569],\n",
      "         [0.2392, 0.1922, 0.1373,  ..., 0.1020, 0.1137, 0.0784],\n",
      "         [0.2118, 0.2196, 0.1765,  ..., 0.0941, 0.1333, 0.0824]],\n",
      "\n",
      "        [[0.4392, 0.4353, 0.4549,  ..., 0.3725, 0.3569, 0.3333],\n",
      "         [0.4392, 0.4314, 0.4471,  ..., 0.3725, 0.3569, 0.3451],\n",
      "         [0.4314, 0.4275, 0.4353,  ..., 0.3843, 0.3725, 0.3490],\n",
      "         ...,\n",
      "         [0.4863, 0.3922, 0.3451,  ..., 0.3804, 0.2510, 0.3333],\n",
      "         [0.4549, 0.4000, 0.3333,  ..., 0.3216, 0.3216, 0.2510],\n",
      "         [0.4196, 0.4118, 0.3490,  ..., 0.3020, 0.3294, 0.2627]],\n",
      "\n",
      "        [[0.1922, 0.1843, 0.2000,  ..., 0.1412, 0.1412, 0.1294],\n",
      "         [0.2000, 0.1569, 0.1765,  ..., 0.1216, 0.1255, 0.1333],\n",
      "         [0.1843, 0.1294, 0.1412,  ..., 0.1333, 0.1333, 0.1294],\n",
      "         ...,\n",
      "         [0.6941, 0.5804, 0.5373,  ..., 0.5725, 0.4235, 0.4980],\n",
      "         [0.6588, 0.5804, 0.5176,  ..., 0.5098, 0.4941, 0.4196],\n",
      "         [0.6275, 0.5843, 0.5176,  ..., 0.4863, 0.5059, 0.4314]]]), 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x14804024A20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#展示图像\n",
    "import PIL\n",
    "ToPIL = torchvision.transforms.ToPILImage()\n",
    "#ToPIL(torchvision.utils.make_grid(L[0])).show()\n",
    "x=0\n",
    "for i,data in enumerate(test_data):\n",
    "    print(data)\n",
    "    x= ToPIL(data[0])\n",
    "    break\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 32, 32])\n",
      "torch.Size([50, 8, 6, 6])\n",
      "torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "cnn = ClassificationCIFAR10()\n",
    "n1=nn.Sequential(nn.Conv2d(3, 4, 3, 1),nn.ReLU(), nn.MaxPool2d(kernel_size=2))\n",
    "n2=nn.Sequential(nn.Conv2d(4, 8, 3, 1),nn.ReLU(), nn.MaxPool2d(kernel_size=2))\n",
    "for i,data in enumerate(test_loader):\n",
    "    print(data[0].size())\n",
    "    print(n2(n1(data[0])).size())\n",
    "    print(cnn(data[0]).size())\n",
    "    break\n",
    "    #print(cnn(data[0]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10的最高正确率高于80的有很多。但是Pytorch官方教程和这个网络的正确率都在50左右。\n",
    "# 分析一下可能因为CIFAR10的图片不统一。例如同样是狗，有的给的狗头，有的给的狗身子。虽然图片小，但是问题是比较复杂的。\n",
    "# 因此目前不太纠结这个"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
