{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "torchvision\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import datetime\n",
    "# torch.manual_seed(1)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "trainset=torchvision.datasets.CIFAR10(\n",
    "    root='./data',train=True,download=True,transform=transform\n",
    ")\n",
    "trainloader=torch.utils.data.DataLoader(\n",
    "    trainset,batch_size=4,shuffle=True,num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001\n",
    "# DOWNLOAD_MNIST = False\n",
    "DOWNLOAD_MNIST=True\n",
    "\n",
    "# train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(), download=DOWNLOAD_MNIST,)\n",
    "# train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_data = trainset\n",
    "train_loader = trainloader\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000].cuda()/255.   # Tensor on GPU\n",
    "test_y = test_data.test_labels[:2000].cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(3, 3,padding=1)\n",
    "        self.conv1 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv3 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv4 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv5 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv6 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv7 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv8 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv9 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv11 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv12 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv13 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv14 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv15 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv16 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv17 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv18 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        self.conv19 = nn.Conv2d(3, 3, 5,padding=2)\n",
    "        #self.conv20 = nn.Conv2d(3, 6, 5)\n",
    "        #self.conv21 = nn.Conv2d(6, 16, 5)\n",
    "        #self.conv3 = nn.Conv2d(16,32,5)\n",
    "        self.fc = nn.Linear(12, 10)\n",
    "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = self.pool(F.relu(self.conv7(x)))\n",
    "        x = self.pool(F.relu(self.conv8(x)))\n",
    "        x = self.pool(F.relu(self.conv9(x)))\n",
    "        x = self.pool(F.relu(self.conv11(x)))\n",
    "        x = self.pool(F.relu(self.conv12(x)))\n",
    "        x = self.pool(F.relu(self.conv13(x)))\n",
    "        x = self.pool(F.relu(self.conv14(x)))\n",
    "        x = self.pool(F.relu(self.conv15(x)))\n",
    "        x = self.pool(F.relu(self.conv16(x)))\n",
    "        x = self.pool(F.relu(self.conv17(x)))\n",
    "        x = self.pool(F.relu(self.conv18(x)))\n",
    "        x = self.pool(F.relu(self.conv19(x)))\n",
    "        #x = self.pool(F.relu(self.conv20(x)))\n",
    "        #x = self.pool(F.relu(self.conv21(x)))\n",
    "        #print(x.size)\n",
    "        #x = self.pool(F.relu(self.conv3(x)))\n",
    "        #x = x.view(-1,12)\n",
    "        x = x.view(-1,12)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.fc3(x)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "cnn.to(device)      # Moves all model parameters and buffers to the GPU.\n",
    "torch.cuda.synchronize()\n",
    "starttime=datetime.datetime.now()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, mydata in enumerate(train_loader,0):\n",
    "        #x,y=mydata\n",
    "        #print(x.size(),y.size())\n",
    "        #print(y)\n",
    "        # !!!!!!!! Change in here !!!!!!!!! #\n",
    "        #b_x = x.to(device)    # Tensor on GPU\n",
    "        b_x=torch.rand(4,3,32,32).to(device)\n",
    "        #b_y=torch.rand(1).to(device)\n",
    "        #b_y = y.to(device)    # Tensor on GPU\n",
    "        #print(b_x.size(),b_y.size())\n",
    "\n",
    "        output = cnn(b_x)\n",
    "        loss = output.sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step)\n",
    "        if step == 200 :\n",
    "            #test_output = cnn(test_x)\n",
    "\n",
    "            # !!!!!!!! Change in here !!!!!!!!! #\n",
    "            #pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()  # move the computation in GPU\n",
    "\n",
    "            #accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "            #print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' ,step)\n",
    "            print(step)\n",
    "            torch.cuda.synchronize()\n",
    "            endtime=datetime.datetime.now()\n",
    "            print((endtime-starttime).seconds)\n",
    "            break\n",
    "\n",
    "#test_output = cnn(test_x[:10])\n",
    "\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "#pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze() # move the computation in GPU\n",
    "\n",
    "#print(pred_y, 'prediction number')\n",
    "#print(test_y[:10], 'real number')\n",
    "torch.cuda.synchronize()\n",
    "endtime=datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes time to load data into the gpu repeatedly.\n",
    "# Be sure to ensure that the dataset is loaded into the GPU before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "cnn.to('cpu')      # Moves all model parameters and buffers to the GPU.\n",
    "torch.cuda.synchronize()\n",
    "starttime=datetime.datetime.now()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for step, mydata in enumerate(train_loader,0):\n",
    "        #x,y=mydata\n",
    "        # !!!!!!!! Change in here !!!!!!!!! #\n",
    "        #b_x = x.to('cpu')    # Tensor on GPU\n",
    "        #b_y = y.to('cpu')    # Tensor on GPU\n",
    "        b_x=torch.rand(4,3,32,32).to('cpu')\n",
    "        #b_y=torch.rand(1).to('cpu')\n",
    "\n",
    "        output = cnn(b_x)\n",
    "        loss = output.sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(step)\n",
    "        if step == 200 :\n",
    "            #test_output = cnn(test_x)\n",
    "\n",
    "            # !!!!!!!! Change in here !!!!!!!!! #\n",
    "            #pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze()  # move the computation in GPU\n",
    "\n",
    "            #accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "            #print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' ,step)\n",
    "            print(step)\n",
    "            torch.cuda.synchronize()\n",
    "            endtime=datetime.datetime.now()\n",
    "            print((endtime-starttime).seconds)\n",
    "            break\n",
    "\n",
    "#test_output = cnn(test_x[:10])\n",
    "\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "#pred_y = torch.max(test_output, 1)[1].cuda().data.squeeze() # move the computation in GPU\n",
    "\n",
    "#print(pred_y, 'prediction number')\n",
    "#print(test_y[:10], 'real number')\n",
    "torch.cuda.synchronize()\n",
    "endtime=datetime.datetime.now()\n",
    "print((endtime-starttime).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6411, 0.7536, 0.4673,  ..., 0.2038, 0.8935, 0.1797],\n",
       "          [0.1394, 0.5587, 0.4537,  ..., 0.1356, 0.8089, 0.3146],\n",
       "          [0.0180, 0.4452, 0.3309,  ..., 0.7740, 0.7439, 0.3765],\n",
       "          ...,\n",
       "          [0.7925, 0.8511, 0.3781,  ..., 0.4316, 0.9071, 0.8988],\n",
       "          [0.1233, 0.5385, 0.6383,  ..., 0.5524, 0.1245, 0.4406],\n",
       "          [0.4328, 0.9553, 0.9439,  ..., 0.1388, 0.3190, 0.3142]],\n",
       "\n",
       "         [[0.1231, 0.3588, 0.0951,  ..., 0.4397, 0.2231, 0.4428],\n",
       "          [0.3078, 0.6073, 0.6455,  ..., 0.6733, 0.9127, 0.5891],\n",
       "          [0.9063, 0.2234, 0.7716,  ..., 0.0673, 0.7392, 0.2163],\n",
       "          ...,\n",
       "          [0.5226, 0.6582, 0.1729,  ..., 0.1941, 0.9276, 0.1430],\n",
       "          [0.0730, 0.2119, 0.3609,  ..., 0.2483, 0.0537, 0.7303],\n",
       "          [0.5956, 0.7739, 0.9652,  ..., 0.5470, 0.3909, 0.1023]],\n",
       "\n",
       "         [[0.3210, 0.7950, 0.8067,  ..., 0.5737, 0.4700, 0.6621],\n",
       "          [0.4034, 0.1065, 0.6316,  ..., 0.4865, 0.1055, 0.7434],\n",
       "          [0.8058, 0.3543, 0.3781,  ..., 0.9135, 0.3685, 0.8906],\n",
       "          ...,\n",
       "          [0.8638, 0.2223, 0.2115,  ..., 0.0456, 0.4522, 0.4514],\n",
       "          [0.9374, 0.0481, 0.7014,  ..., 0.5314, 0.5970, 0.1033],\n",
       "          [0.6946, 0.1300, 0.2476,  ..., 0.3175, 0.8146, 0.1999]]],\n",
       "\n",
       "\n",
       "        [[[0.8058, 0.1596, 0.7638,  ..., 0.3740, 0.2255, 0.6578],\n",
       "          [0.2940, 0.2471, 0.2374,  ..., 0.4384, 0.2743, 0.4251],\n",
       "          [0.6768, 0.9181, 0.1685,  ..., 0.8084, 0.3941, 0.0013],\n",
       "          ...,\n",
       "          [0.4152, 0.8682, 0.2437,  ..., 0.2309, 0.9990, 0.8520],\n",
       "          [0.9487, 0.4750, 0.8789,  ..., 0.1102, 0.1339, 0.7566],\n",
       "          [0.6985, 0.1536, 0.9315,  ..., 0.3194, 0.6088, 0.9405]],\n",
       "\n",
       "         [[0.6407, 0.7676, 0.1606,  ..., 0.4449, 0.8782, 0.3579],\n",
       "          [0.4889, 0.8337, 0.0399,  ..., 0.6180, 0.5782, 0.6644],\n",
       "          [0.8407, 0.4967, 0.4840,  ..., 0.3732, 0.7280, 0.8941],\n",
       "          ...,\n",
       "          [0.1592, 0.7907, 0.5173,  ..., 0.3855, 0.8473, 0.7148],\n",
       "          [0.5993, 0.0747, 0.2321,  ..., 0.4404, 0.2942, 0.8963],\n",
       "          [0.0265, 0.3908, 0.6772,  ..., 0.0479, 0.2698, 0.4830]],\n",
       "\n",
       "         [[0.1194, 0.2560, 0.5940,  ..., 0.0090, 0.5014, 0.1094],\n",
       "          [0.7199, 0.4766, 0.6352,  ..., 0.2091, 0.6191, 0.2871],\n",
       "          [0.5852, 0.7177, 0.6664,  ..., 0.5387, 0.3045, 0.5134],\n",
       "          ...,\n",
       "          [0.7135, 0.5806, 0.2800,  ..., 0.3781, 0.0977, 0.7891],\n",
       "          [0.3159, 0.7857, 0.6490,  ..., 0.9602, 0.2954, 0.3287],\n",
       "          [0.4626, 0.6486, 0.6408,  ..., 0.9922, 0.9237, 0.0229]]],\n",
       "\n",
       "\n",
       "        [[[0.4824, 0.2232, 0.7954,  ..., 0.9056, 0.4815, 0.7523],\n",
       "          [0.5651, 0.5065, 0.2469,  ..., 0.1263, 0.2264, 0.1207],\n",
       "          [0.4782, 0.3351, 0.8193,  ..., 0.6344, 0.1262, 0.1589],\n",
       "          ...,\n",
       "          [0.8977, 0.7718, 0.6426,  ..., 0.7331, 0.4394, 0.2300],\n",
       "          [0.6259, 0.0907, 0.9947,  ..., 0.9667, 0.3318, 0.0956],\n",
       "          [0.3185, 0.5962, 0.7754,  ..., 0.1402, 0.9427, 0.8056]],\n",
       "\n",
       "         [[0.3799, 0.6763, 0.9831,  ..., 0.7442, 0.2800, 0.6834],\n",
       "          [0.0278, 0.4140, 0.6581,  ..., 0.3374, 0.1145, 0.4516],\n",
       "          [0.9580, 0.2134, 0.6746,  ..., 0.6356, 0.6528, 0.9143],\n",
       "          ...,\n",
       "          [0.9404, 0.0081, 0.5981,  ..., 0.4204, 0.5070, 0.6274],\n",
       "          [0.9404, 0.5947, 0.9514,  ..., 0.5621, 0.1319, 0.6407],\n",
       "          [0.2459, 0.5376, 0.2105,  ..., 0.2308, 0.4457, 0.3381]],\n",
       "\n",
       "         [[0.8352, 0.9748, 0.6030,  ..., 0.2840, 0.3726, 0.7767],\n",
       "          [0.1705, 0.2768, 0.2454,  ..., 0.5976, 0.2854, 0.3390],\n",
       "          [0.3979, 0.7411, 0.6439,  ..., 0.4453, 0.1247, 0.7071],\n",
       "          ...,\n",
       "          [0.9324, 0.9960, 0.4883,  ..., 0.2333, 0.8533, 0.0098],\n",
       "          [0.1232, 0.3776, 0.4606,  ..., 0.3482, 0.0745, 0.8722],\n",
       "          [0.9408, 0.4794, 0.2670,  ..., 0.0008, 0.7347, 0.0698]]],\n",
       "\n",
       "\n",
       "        [[[0.2641, 0.3278, 0.7272,  ..., 0.3338, 0.0818, 0.0127],\n",
       "          [0.6683, 0.3921, 0.7829,  ..., 0.0644, 0.4054, 0.4898],\n",
       "          [0.6904, 0.8561, 0.3027,  ..., 0.6786, 0.3381, 0.1599],\n",
       "          ...,\n",
       "          [0.3548, 0.5623, 0.4579,  ..., 0.2386, 0.3080, 0.4997],\n",
       "          [0.3358, 0.6107, 0.9124,  ..., 0.0767, 0.3694, 0.2281],\n",
       "          [0.1232, 0.5622, 0.8482,  ..., 0.5707, 0.8000, 0.9173]],\n",
       "\n",
       "         [[0.9914, 0.5594, 0.1531,  ..., 0.5258, 0.3750, 0.5723],\n",
       "          [0.4713, 0.3872, 0.8653,  ..., 0.1769, 0.2507, 0.6584],\n",
       "          [0.1461, 0.5465, 0.7009,  ..., 0.1931, 0.5418, 0.1911],\n",
       "          ...,\n",
       "          [0.1271, 0.9490, 0.4649,  ..., 0.6405, 0.7362, 0.4388],\n",
       "          [0.8983, 0.3374, 0.3471,  ..., 0.0591, 0.7669, 0.3174],\n",
       "          [0.6084, 0.9274, 0.9136,  ..., 0.6544, 0.8378, 0.9016]],\n",
       "\n",
       "         [[0.1738, 0.6673, 0.7215,  ..., 0.5227, 0.8313, 0.2698],\n",
       "          [0.7815, 0.9542, 0.0720,  ..., 0.1138, 0.2000, 0.7970],\n",
       "          [0.5952, 0.4801, 0.7315,  ..., 0.8100, 0.5579, 0.1516],\n",
       "          ...,\n",
       "          [0.3555, 0.6432, 0.2515,  ..., 0.4378, 0.8400, 0.7179],\n",
       "          [0.4959, 0.5203, 0.0082,  ..., 0.2731, 0.4751, 0.1569],\n",
       "          [0.7549, 0.8755, 0.6204,  ..., 0.2781, 0.4103, 0.2334]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.Tensor([[1,2],[2,3]])\n",
    "x.sum()\n",
    "x=torch.rand(4,3,32,32)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
