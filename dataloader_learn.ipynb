{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = torchvision.datasets.MNIST(root='./data',train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.utils.data.TensorDataset(torch.randn(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from 'E:\\\\Miniconda3\\\\lib\\\\site-packages\\\\torch\\\\__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x is torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = torch.utils.data.Dataset()\n",
    "type(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([[ 0.8021, -0.3526, -0.0752, -0.6719,  1.7437],\n",
      "        [-1.4389,  1.3476,  0.1970, -1.0503, -1.3953],\n",
      "        [ 0.3370,  0.7207,  0.1626,  1.8064, -0.3763],\n",
      "        [ 0.4601, -1.0105,  0.3318,  2.0603, -0.0022]]),)\n",
      "1 (tensor([[-1.2260,  0.3120,  0.5564,  0.8900,  0.2057],\n",
      "        [-0.5247,  1.2015,  0.9140,  1.1060,  0.2902],\n",
      "        [ 1.5970,  1.5590,  0.2258, -1.4159, -1.2365],\n",
      "        [-0.3014, -0.0961,  0.2864, -0.8048,  0.3339]]),)\n",
      "2 (tensor([[ 1.9720, -0.0727,  0.0355,  0.7309,  1.9727],\n",
      "        [ 0.4253,  0.0160, -1.0518, -0.5768, -0.6382],\n",
      "        [-0.5055,  0.2285,  1.1338, -2.1306,  0.7391],\n",
      "        [-0.3767,  0.3518, -0.0425, -0.1989,  0.3876]]),)\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(x,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "0 tensor([-0.4251,  0.1007,  0.6064])\n",
      "1 tensor([-0.5888,  1.2094,  0.4805])\n",
      "2 tensor([2.3184, 2.1111, 1.8234])\n",
      "3 tensor([-0.3246, -1.0995,  0.4846])\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(torch.utils.data.ConcatDataset([[1,2,3],[4,5]])):\n",
    "    print(i,data)\n",
    "    \n",
    "for i,data in enumerate(torch.utils.data.ConcatDataset([torch.randn(2,3),torch.randn(2,3)])):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issubclass(torch.utils.data.Dataset,torch.utils.data.TensorDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.utils.data.TensorDataset(torch.randn(3,4,5))\n",
    "x2 = torch.utils.data.TensorDataset(torch.randn(7,4,5))\n",
    "y = torch.utils.data.ConcatDataset([x1,x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([[ 0.2158,  0.2062, -0.2186, -0.5231,  0.6843],\n",
      "        [-0.5952,  0.3397, -0.4981,  0.4368, -0.7412],\n",
      "        [ 0.2432, -0.6873, -0.5372,  0.2044, -0.6463],\n",
      "        [-1.6940,  0.9701,  0.7869,  0.1734, -0.2563]]),)\n",
      "1 (tensor([[ 0.6965, -0.7890, -1.7306,  1.8866, -0.6964],\n",
      "        [-1.8898,  2.0571,  0.5453, -0.8427, -0.0385],\n",
      "        [ 0.9251,  1.6461,  0.2704,  0.2044, -1.5475],\n",
      "        [ 0.6541,  0.9796,  0.5412,  1.0931, -0.3318]]),)\n",
      "2 (tensor([[-0.7468,  1.6969,  0.7146,  2.3621, -0.6968],\n",
      "        [-2.3497, -0.1778,  1.4080,  0.7139, -1.6031],\n",
      "        [ 1.0523, -1.4756, -0.1781,  0.3348, -1.9636],\n",
      "        [ 1.3625,  0.0807,  0.2612, -0.3862,  0.7863]]),)\n",
      "3 (tensor([[ 0.0735, -1.2006,  1.5954,  0.2795, -0.8105],\n",
      "        [-1.1734,  1.8091, -1.9099,  0.3667,  0.3930],\n",
      "        [ 0.2563, -0.8523,  0.4123,  1.6370, -0.2620],\n",
      "        [ 0.3622,  0.5156,  0.9839, -0.0736,  1.3973]]),)\n",
      "4 (tensor([[-0.9745, -0.2313,  2.5851,  0.9042,  0.0479],\n",
      "        [ 0.7829,  0.5923, -0.7886,  0.2468, -0.3822],\n",
      "        [-0.1953,  0.1431, -0.5939,  0.4001, -0.5228],\n",
      "        [ 0.6033,  1.0847, -0.5994,  0.0343,  2.1981]]),)\n",
      "5 (tensor([[-0.2792,  0.4630,  0.1424, -0.1028,  0.6298],\n",
      "        [-1.4734, -1.9104, -0.3475, -1.8337, -0.0983],\n",
      "        [ 0.5457,  0.5093, -0.4993,  0.2159, -0.7755],\n",
      "        [-0.2664, -0.2567, -0.9880, -0.7618,  2.6597]]),)\n",
      "6 (tensor([[-1.4766, -0.7831,  1.0616, -0.9575, -0.4748],\n",
      "        [ 0.6045, -1.1325,  0.5123, -1.3219,  0.3494],\n",
      "        [-1.1438, -0.2893,  0.0695, -0.7357,  0.6667],\n",
      "        [-0.4461, -0.2168, -0.6378,  0.0666, -1.8970]]),)\n",
      "7 (tensor([[ 0.4877, -1.3848,  0.5901,  0.8138, -0.0566],\n",
      "        [ 0.3733, -1.0241,  0.5154, -1.4544,  0.1001],\n",
      "        [ 1.3014,  0.1593,  1.1729,  0.8457,  1.3966],\n",
      "        [-0.6780,  1.6925, -0.7205,  0.1579, -1.3929]]),)\n",
      "8 (tensor([[ 0.1833,  0.9781, -0.2152, -0.3226,  0.0464],\n",
      "        [-0.3813,  0.5621,  0.4062, -0.5599, -0.6502],\n",
      "        [ 1.2624, -0.5501,  1.3642, -0.3586,  2.9595],\n",
      "        [ 1.9956, -0.7187, -1.3320, -1.8823, -2.2728]]),)\n",
      "9 (tensor([[ 1.5280, -0.6058, -0.1904, -0.1124,  0.0919],\n",
      "        [ 2.2348, -0.7739,  0.6776, -0.7591,  1.0616],\n",
      "        [ 0.2487,  1.1924, -1.7785, -0.2921,  0.7838],\n",
      "        [-0.1532,  0.1854, -0.6044,  1.3454,  0.3562]]),)\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(y,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y1 = torch.utils.data.Subset(y,[4,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([[-0.4220, -1.8666, -1.0239,  0.0946,  0.5530],\n",
      "        [ 0.2947, -0.1728,  0.2560, -1.5870, -0.5373],\n",
      "        [ 2.6154,  2.1633, -0.2950, -0.1592, -0.5671],\n",
      "        [ 0.0709,  1.7260, -0.5593,  1.2639, -0.3624]]),)\n",
      "1 (tensor([[-0.5227,  1.9633,  2.1354, -0.7819,  0.6302],\n",
      "        [ 0.2233, -1.2557,  0.7028, -0.1601, -0.1545],\n",
      "        [-0.6004,  0.9836, -0.7924,  0.4814, -0.9518],\n",
      "        [ 1.1780, -3.2539, -0.4472, -1.4975, -0.2441]]),)\n",
      "2 (tensor([[ 0.6913, -0.6255,  0.4476,  1.3486, -0.6240],\n",
      "        [ 1.5558, -2.0750,  1.0992,  0.6092, -0.4415],\n",
      "        [-0.5143, -2.2818, -0.7728, -0.7029, -2.2658],\n",
      "        [ 1.2100,  0.8575, -0.8635, -1.2276,  1.1332]]),)\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(y1,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([ 8, 19, 18, 16]), tensor([ 64, 361, 324, 256])]\n",
      "1 [tensor([10, 15,  3, 11]), tensor([100, 225,   9, 121])]\n",
      "2 [tensor([ 4, 17,  6,  5]), tensor([ 16, 289,  36,  25])]\n",
      "3 [tensor([13,  7,  9,  0]), tensor([169,  49,  81,   0])]\n",
      "4 [tensor([12, 14,  2,  1]), tensor([144, 196,   4,   1])]\n"
     ]
    }
   ],
   "source": [
    "myDataset = [(i,i*i) for i in range(20)]\n",
    "y = torch.utils.data.DataLoader(myDataset,shuffle=True,batch_size=4)\n",
    "for index,data in enumerate(y):\n",
    "    print(index,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[ 0.,  4.,  8., 12., 16.],\n",
      "        [ 0.,  5., 10., 15., 20.],\n",
      "        [ 0.,  8., 16., 24., 32.]]), tensor([[4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [8., 8., 8., 8.]])]\n",
      "1 [tensor([[ 0.,  2.,  4.,  6.,  8.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  9., 18., 27., 36.]]), tensor([[2., 2., 2., 2.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [9., 9., 9., 9.]])]\n",
      "2 [tensor([[ 0.,  7., 14., 21., 28.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 0.,  3.,  6.,  9., 12.]]), tensor([[7., 7., 7., 7.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [3., 3., 3., 3.]])]\n",
      "3 [tensor([[ 0.,  6., 12., 18., 24.]]), tensor([[6., 6., 6., 6.]])]\n"
     ]
    }
   ],
   "source": [
    "temp = [([x*i for x in range(5)],[i,i,i,i]) for i in range(10)]\n",
    "temp = list(map(lambda x: (torch.Tensor(x[0]),torch.Tensor(x[1])),temp)) # 如果这里不转换成tensor，可能被拆开重组。\n",
    "# 试试不转换直接转换为temp\n",
    "y2 = torch.utils.data.DataLoader(temp,shuffle=True,batch_size=3)\n",
    "for i,data in enumerate(y2,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [([x*i for x in range(5)],i) for i in range(10)]\n",
    "temp = list(map(lambda x: (torch.Tensor(x[0]),torch.Tensor([x[1]])),temp)) # 如果把标签也转化成Tensor会多套一层（原子结构没有办法直接转换成张量）\n",
    "y2 = torch.utils.data.DataLoader(temp,shuffle=True,batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 0.,  5., 10., 15., 20.],\n",
      "        [ 0.,  3.,  6.,  9., 12.]]), tensor([[1.],\n",
      "        [5.],\n",
      "        [3.]])]\n",
      "1 [tensor([[ 0.,  8., 16., 24., 32.],\n",
      "        [ 0.,  7., 14., 21., 28.],\n",
      "        [ 0.,  9., 18., 27., 36.]]), tensor([[8.],\n",
      "        [7.],\n",
      "        [9.]])]\n",
      "2 [tensor([[ 0.,  6., 12., 18., 24.],\n",
      "        [ 0.,  2.,  4.,  6.,  8.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.]]), tensor([[6.],\n",
      "        [2.],\n",
      "        [0.]])]\n",
      "3 [tensor([[ 0.,  4.,  8., 12., 16.]]), tensor([[4.]])]\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(y2,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[tensor([0, 0, 0]), tensor([5, 0, 7]), tensor([10,  0, 14]), tensor([15,  0, 21]), tensor([20,  0, 28])], tensor([5, 0, 7])]\n",
      "1 [[tensor([0, 0, 0]), tensor([4, 6, 8]), tensor([ 8, 12, 16]), tensor([12, 18, 24]), tensor([16, 24, 32])], tensor([4, 6, 8])]\n",
      "2 [[tensor([0, 0, 0]), tensor([3, 1, 2]), tensor([6, 2, 4]), tensor([9, 3, 6]), tensor([12,  4,  8])], tensor([3, 1, 2])]\n",
      "3 [[tensor([0]), tensor([9]), tensor([18]), tensor([27]), tensor([36])], tensor([9])]\n"
     ]
    }
   ],
   "source": [
    "temp = [([x*i for x in range(5)],i) for i in range(10)]\n",
    "y2 = torch.utils.data.DataLoader(temp,shuffle=True,batch_size=3)\n",
    "for i,data in enumerate(y2,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "temp = [([x*i for x in range(5)],i) for i in range(10)]\n",
    "temp = list(map(lambda x: (torch.Tensor(x[0]),x[1]),temp)) # 如果这里不转换成tensor，可能被拆开重组。\n",
    "# 试试不转换直接转换为temp\n",
    "print(len(temp))\n",
    "# 所有接受dataset作为参数的函数，不一定要是一个dataset对象，只要是可迭代就可以\n",
    "y3 = torch.utils.data.random_split(temp,[3,0,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (tensor([ 0.,  4.,  8., 12., 16.]), 4)\n",
      "1 (tensor([ 0.,  9., 18., 27., 36.]), 9)\n",
      "2 (tensor([0., 1., 2., 3., 4.]), 1)\n",
      "0 (tensor([ 0.,  3.,  6.,  9., 12.]), 3)\n",
      "1 (tensor([0., 0., 0., 0., 0.]), 0)\n",
      "2 (tensor([ 0.,  8., 16., 24., 32.]), 8)\n",
      "0 (tensor([ 0.,  6., 12., 18., 24.]), 6)\n",
      "1 (tensor([ 0.,  7., 14., 21., 28.]), 7)\n",
      "2 (tensor([0., 2., 4., 6., 8.]), 2)\n",
      "3 (tensor([ 0.,  5., 10., 15., 20.]), 5)\n"
     ]
    }
   ],
   "source": [
    "for dataset in y3:\n",
    "    for i,data in enumerate(dataset,0):\n",
    "        print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 1., 2., 3., 4.],\n",
      "        [0., 2., 4., 6., 8.]]), tensor([0, 1, 2])]\n",
      "1 [tensor([[ 0.,  3.,  6.,  9., 12.],\n",
      "        [ 0.,  4.,  8., 12., 16.],\n",
      "        [ 0.,  5., 10., 15., 20.]]), tensor([3, 4, 5])]\n",
      "2 [tensor([[ 0.,  6., 12., 18., 24.],\n",
      "        [ 0.,  7., 14., 21., 28.],\n",
      "        [ 0.,  8., 16., 24., 32.]]), tensor([6, 7, 8])]\n",
      "3 [tensor([[ 0.,  9., 18., 27., 36.]]), tensor([9])]\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(y3,0):\n",
    "    print(i,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c7d03b45697f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my3s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \"\"\"\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "y3s = torch.utils.data.random_split(y3,[2,1,3,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
